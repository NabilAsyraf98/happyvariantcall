{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vcf(input_file):\n",
    "    \"\"\"\n",
    "    To collect chr and position information of false positives and false negatives from hap.py output vcf\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    #create dictionary to store results of FN and FP\n",
    "    output_dict=defaultdict(list)\n",
    "\n",
    "    with open(input_file, 'r') as infile:\n",
    "        for line in infile:\n",
    "            #go to output of VCF\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            #split line into columns\n",
    "            columns=line.strip().split('\\t')\n",
    "            #only look at valid VCF lines that have 10 or 11 columns\n",
    "            if len(columns) < 11:\n",
    "                continue\n",
    "\n",
    "             #in VCF file, truth is column 9 while QUERY is column 10\n",
    "            truth_field=columns[9]\n",
    "            query_field=columns[10]\n",
    "            \n",
    "              #split by ':'\n",
    "            truth_parts=truth_field.split(':')\n",
    "            query_parts=query_field.split(':')\n",
    "\n",
    "            #check if FN is in truth field and FP is in query field\n",
    "            if truth_parts[1] == 'FN':\n",
    "                output_dict['FN'].append((columns[0],columns[1],truth_parts[4]))\n",
    "\n",
    "            if query_parts[1] == 'FP':\n",
    "                output_dict['FP'].append((columns[0], columns[1],query_parts[4]))\n",
    "    return output_dict\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_falses=parse_vcf(\"chr20.vcf\") #hap.py output vcf file\n",
    "#separate them to FP and FN\n",
    "false_positives= list(collection_falses['FP'])\n",
    "false_negatives=list(collection_falses['FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_metrics(input_vcf_file, coordinates):\n",
    "    \"\"\"\n",
    "    for each false/true coordinate, go through Clair3 output full alignment vcf file and find variant quality and read depth\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    collection=defaultdict(list)\n",
    "\n",
    "    #read VCF into a dictionary\n",
    "    vcf_dict={}\n",
    "    with open(input_vcf_file, 'r') as infile:\n",
    "            for line in infile:\n",
    "            #go to output of VCF\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                 #split line into columns\n",
    "                columns=line.strip().split('\\t')\n",
    "                chromosome=columns[0]\n",
    "                pos=columns[1]\n",
    "                sample=columns[9]\n",
    "                parts=sample.split(':')\n",
    "                score=parts[1]\n",
    "                depth=parts[2]\n",
    "                vcf_dict[(chromosome,pos)]=(score,depth)\n",
    "    count=0\n",
    "    found =0\n",
    "    for variant in coordinates:\n",
    "        chro=variant[0]\n",
    "        posi=variant[1]\n",
    "        if (chro,posi) in vcf_dict:\n",
    "             collection[(chro,posi)] = (variant[2],vcf_dict[(chro,posi)][0],vcf_dict[(chro,posi)][1])\n",
    "             found +=1\n",
    "        else:\n",
    "             count +=1\n",
    "    print(f\"Missing variants is {count}!\")    \n",
    "    print(f\"Found variants is {found}!\")\n",
    "    return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing variants is 136!\n",
      "Found variants is 2949!\n"
     ]
    }
   ],
   "source": [
    "metrics = collect_metrics(\"clair3_work/run4/run4_full_alignment.vcf\", false_positives)\n",
    "with open('false_positives_HG002.txt', 'w') as file:\n",
    "    for key, value in metrics.items():\n",
    "        file.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_TP_coordinates(input_file):\n",
    "    \"\"\"\n",
    "    Collect True Positives chr and position information from hap.py output vcf file\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    output_dict=defaultdict(list)\n",
    "\n",
    "    with open(input_file, 'r') as infile:\n",
    "        for line in infile:\n",
    "            #go to output of VCF\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            #split line into columns\n",
    "            columns=line.strip().split('\\t')\n",
    "            #only look at valid VCF lines that have 10 or 11 columns\n",
    "            if len(columns) < 11:\n",
    "                continue\n",
    "\n",
    "             #in VCF file, truth is column 9 \n",
    "            truth_field=columns[9]\n",
    "            \n",
    "              #split by ':'\n",
    "            truth_parts=truth_field.split(':')\n",
    "            \n",
    "            if truth_parts[1] == 'TP':\n",
    "\n",
    "                output_dict['TP'].append((columns[0],columns[1],truth_parts[4]))\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing variants is 14!\n",
      "Found variants is 44084!\n"
     ]
    }
   ],
   "source": [
    "collection_TP=collect_TP_coordinates(\"chr20.vcf\")\n",
    "\n",
    "intermid=list(collection_TP.values())\n",
    "true_TP=intermid[0]\n",
    "metrics = collect_metrics(\"clair3_work/run4/run4_full_alignment.vcf\", true_TP)\n",
    "with open('TP_HG002.txt', 'w') as file:\n",
    "    for key, value in metrics.items():\n",
    "        file.write(f\"{key}: {value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(data_list):\n",
    "    \"\"\"\n",
    "    Calculate basic statistics of genotype quality and read depth for TP and FP calls\n",
    "    \"\"\"\n",
    "    import statistics\n",
    "    if len(data_list)==0:\n",
    "        return {\"all metrics 0\"}\n",
    "    else:\n",
    "        data_sorted=sorted(data_list)\n",
    "        return {\n",
    "            \"mean\": round(statistics.mean(data_sorted), 3),\n",
    "            \"median\": round(statistics.median(data_sorted), 3),\n",
    "            \"min\": round(min(data_sorted), 3),\n",
    "            \"max\": round(max(data_sorted), 3),\n",
    "            \"Q3\": round(statistics.quantiles(data_sorted, n=4)[2], 3),\n",
    "            \"Q1\": round(statistics.quantiles(data_sorted, n=4)[0], 3),\n",
    "            \"IQR\": round(statistics.quantiles(data_sorted, n=4)[2], 3) - round(statistics.quantiles(data_sorted, n=4)[0], 3)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(TP_file,FP_file):\n",
    "    #create datalist for genotype scores and depth for SNPs and indels for both True positives and false positives\n",
    "    FP_GT_scores_SNP=list()\n",
    "    FP_depth_SNP=list()\n",
    "    FP_GT_scores_INDEL=list()\n",
    "    FP_depth_INDEL=list()\n",
    "\n",
    "    TP_GT_scores_SNP=list()\n",
    "    TP_depth_SNP=list()\n",
    "    TP_GT_scores_INDEL=list()\n",
    "    TP_depth_INDEL=list()\n",
    "    \n",
    "    with open(TP_file,'r') as infile:\n",
    "        for line in infile:\n",
    "            columns=line.split(':')\n",
    "            variant_info=columns[1].strip().strip(\"()\")\n",
    "            subparts=variant_info.split(\",\")\n",
    "            #strip all troublesome characters and make it clean\n",
    "            variant_type=subparts[0].strip(\"() '\\\"\") \n",
    "            GTscore=float(subparts[1].strip(\"() '\\\"\"))\n",
    "            depth=float(subparts[2].strip(\"() '\\\"\")) \n",
    "\n",
    "            if variant_type == \"SNP\":\n",
    "                TP_GT_scores_SNP.append(GTscore)\n",
    "                TP_depth_SNP.append(depth)\n",
    "            elif variant_type == 'INDEL':\n",
    "                TP_GT_scores_INDEL.append(GTscore)\n",
    "                TP_depth_INDEL.append(depth)\n",
    "    \n",
    "    with open(FP_file,'r') as infile:\n",
    "        for line in infile:\n",
    "            columns=line.split(':')\n",
    "            variant_info=columns[1].strip().strip(\"()\")\n",
    "            subparts=variant_info.split(\",\")\n",
    "            #strip all troublesome characters and make it clean\n",
    "            variant_type=subparts[0].strip(\"() '\\\"\") \n",
    "            GTscore=float(subparts[1].strip(\"() '\\\"\"))\n",
    "            depth=float(subparts[2].strip(\"() '\\\"\")) \n",
    "\n",
    "            if variant_type == \"SNP\":\n",
    "                FP_GT_scores_SNP.append(GTscore)\n",
    "                FP_depth_SNP.append(depth)\n",
    "            elif variant_type == 'INDEL':\n",
    "                FP_GT_scores_INDEL.append(GTscore)\n",
    "                FP_depth_INDEL.append(depth)\n",
    "                \n",
    "    # Print summary stats\n",
    "    print(\"== TRUE POSITIVE SNP ==\")\n",
    "    print(\"GT Score:\", summary_stats(TP_GT_scores_SNP))\n",
    "    print(\"Depth   :\", summary_stats(TP_depth_SNP))\n",
    "    print(\"\\n== TRUE POSITIVE INDEL ==\")\n",
    "    print(\"GT Score:\", summary_stats(TP_GT_scores_INDEL))\n",
    "    print(\"Depth   :\", summary_stats(TP_depth_INDEL))\n",
    "    print(\"\\n== FALSE POSITIVE SNP ==\")\n",
    "    print(\"GT Score:\", summary_stats(FP_GT_scores_SNP))\n",
    "    print(\"Depth   :\", summary_stats(FP_depth_SNP))\n",
    "    print(\"\\n== FALSE POSITIVE INDEL ==\")\n",
    "    print(\"GT Score:\", summary_stats(FP_GT_scores_INDEL))\n",
    "    print(\"Depth   :\", summary_stats(FP_depth_INDEL))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== TRUE POSITIVE SNP ==\n",
      "GT Score: {'mean': 24.504, 'median': 25.0, 'min': 0.0, 'max': 110.0, 'Q3': 26.0, 'Q1': 23.0, 'IQR': 3.0}\n",
      "Depth   : {'mean': 27.687, 'median': 27.0, 'min': 8.0, 'max': 57.0, 'Q3': 31.0, 'Q1': 24.0, 'IQR': 7.0}\n",
      "\n",
      "== TRUE POSITIVE INDEL ==\n",
      "GT Score: {'mean': 14.565, 'median': 17.0, 'min': 0.0, 'max': 28.0, 'Q3': 20.0, 'Q1': 9.0, 'IQR': 11.0}\n",
      "Depth   : {'mean': 27.618, 'median': 27.0, 'min': 10.0, 'max': 55.0, 'Q3': 31.0, 'Q1': 24.0, 'IQR': 7.0}\n",
      "\n",
      "== FALSE POSITIVE SNP ==\n",
      "GT Score: {'mean': 13.32, 'median': 14.0, 'min': 0.0, 'max': 24.0, 'Q3': 16.0, 'Q1': 11.0, 'IQR': 5.0}\n",
      "Depth   : {'mean': 33.878, 'median': 35.0, 'min': 13.0, 'max': 43.0, 'Q3': 37.0, 'Q1': 33.0, 'IQR': 4.0}\n",
      "\n",
      "== FALSE POSITIVE INDEL ==\n",
      "GT Score: {'mean': 1.768, 'median': 0.0, 'min': 0.0, 'max': 23.0, 'Q3': 3.0, 'Q1': 0.0, 'IQR': 3.0}\n",
      "Depth   : {'mean': 26.311, 'median': 26.0, 'min': 10.0, 'max': 54.0, 'Q3': 30.0, 'Q1': 22.0, 'IQR': 8.0}\n"
     ]
    }
   ],
   "source": [
    "comparison(\"TP_HG002.txt\",\"false_positives_HG002.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
